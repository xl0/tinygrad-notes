{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - The life of a UOp tree\n",
    "> From Tensor to code and result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CPU\"] = \"1\"\n",
    "os.environ[\"DEBUG\"]=\"4\"\n",
    "os.environ[\"NOOPT\"]=\"1\"\n",
    "\n",
    "from tinygrad import Tensor, dtypes, TinyJit\n",
    "from tinygrad.ops import UOp, Ops, PatternMatcher, UPat, graph_rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we are at a point where we can look in more detail at what happens to a UOp tree on its way to become the result.\n",
    "\n",
    "We will take the `.arange()` tree from the previous chapter as an example.\n",
    "\n",
    "We will run with `NOOPT=1` for now, and look at the optimizations in the next chapter.\n",
    "\n",
    "Some code I quote from TinyGrad will be simplified, and it will skip some of the branches not taken. It might be useful to follow along with the actual code as you go through this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
       "  UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
       "    UOp(Ops.RESHAPE, dtypes.float, arg=(8,), src=(\n",
       "      UOp(Ops.REDUCE_AXIS, dtypes.float, arg=(Ops.ADD, (1,)), src=(\n",
       "        UOp(Ops.PERMUTE, dtypes.float, arg=(1, 0), src=(\n",
       "          UOp(Ops.RESHAPE, dtypes.float, arg=(8, 8), src=(\n",
       "            UOp(Ops.RESHAPE, dtypes.float, arg=(8, 8, 1), src=(\n",
       "              UOp(Ops.SHRINK, dtypes.float, arg=((0, 8), (0, 8)), src=(\n",
       "                UOp(Ops.RESHAPE, dtypes.float, arg=(8, 16), src=(\n",
       "                  UOp(Ops.SHRINK, dtypes.float, arg=((0, 128),), src=(\n",
       "                    UOp(Ops.RESHAPE, dtypes.float, arg=(135,), src=(\n",
       "                      UOp(Ops.EXPAND, dtypes.float, arg=(9, 15), src=(\n",
       "                        UOp(Ops.RESHAPE, dtypes.float, arg=(1, 15), src=(\n",
       "                          UOp(Ops.PAD, dtypes.float, arg=((7, 0),), src=(\n",
       "                            UOp(Ops.EXPAND, dtypes.float, arg=(8,), src=(\n",
       "                              UOp(Ops.RESHAPE, dtypes.float, arg=(1,), src=(\n",
       "                                UOp(Ops.CONST, dtypes.float, arg=0.2, src=(\n",
       "                                  x16:=UOp(Ops.VIEW, dtypes.void, arg=ShapeTracker(views=(View(shape=(), strides=(), offset=0, mask=None, contiguous=True),)), src=(\n",
       "                                    UOp(Ops.DEVICE, dtypes.void, arg='CPU', src=()),)),)),)),)),)),)),)),)),)),)),)),)),)),)),)),)),\n",
       "    UOp(Ops.EXPAND, dtypes.float, arg=(8,), src=(\n",
       "      UOp(Ops.RESHAPE, dtypes.float, arg=(1,), src=(\n",
       "        UOp(Ops.CONST, dtypes.float, arg=0.3, src=(\n",
       "           x16,)),)),)),)),\n",
       "  UOp(Ops.EXPAND, dtypes.float, arg=(8,), src=(\n",
       "    UOp(Ops.RESHAPE, dtypes.float, arg=(1,), src=(\n",
       "      UOp(Ops.CONST, dtypes.float, arg=1.5, src=(\n",
       "         x16,)),)),)),))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Tensor.arange(0.5, 2, 0.2) + 1.5 # Start, stop, step => [0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9] + 1.5\n",
    "a.lazydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, step by step.\n",
    "\n",
    "`a.realize()`:\n",
    "```py\n",
    "class Tensor\n",
    "    ...\n",
    "    def realize(self, *lst:Tensor, do_update_stats=True) -> Tensor:\n",
    "        \"\"\"Triggers the computation needed to create these Tensor(s).\"\"\"\n",
    "        run_schedule(*self.schedule_with_vars(*lst), do_update_stats=do_update_stats)\n",
    "        return self\n",
    "```\n",
    "\n",
    "Looks like we need to call `schedule_with_vars()` on the tensor, and pass the result to `run_schedule()`. I'm not sure what's the purpose of the extra tensors (`lst`), but it's empty in out case.\n",
    "\n",
    "\n",
    "```py\n",
    "  def schedule_with_vars(self, *lst:Tensor) -> tuple[list[ScheduleItem], dict[Variable, int]]:\n",
    "    \"NOTE: A Tensor can only be scheduled once.\"\n",
    "    big_sink = UOp.sink(*[x.lazydata for x in (self,)+lst])\n",
    "\n",
    "    # verify Tensors match the spec\n",
    "    if __debug__: type_verify(list(big_sink.toposort), tensor_uop_spec)\n",
    "\n",
    "    schedule, var_vals, becomes_map = create_schedule_with_vars(big_sink)\n",
    "    _apply_map_to_tensors(becomes_map)\n",
    "    return memory_planner(schedule), var_vals\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the first step is to wrap the UOp tree in a `SINK` UOp,\n",
    "```py\n",
    "  def sink(self, *srcs:UOp, **kwargs): return UOp(Ops.SINK, dtypes.void, (self,)+srcs, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UOp(Ops.SINK, dtypes.void, arg=None, src=(\n",
      "  UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
      "    UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
      "      ...\n"
     ]
    }
   ],
   "source": [
    "big_sink = a.lazydata.sink()\n",
    "print(f\"{\"\\n\".join(str(big_sink).splitlines()[:3] + [\"      ...\"])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform the `type_verify`, mentioned in the chapter on the Pattern Matcher.\n",
    "`tinygrad/spec.py`:\n",
    "```py\n",
    "def type_verify(uops:list[UOp], *extra_specs:PatternMatcher):\n",
    "  specs = [spec, *extra_specs]\n",
    "  for i,u in enumerate(uops):\n",
    "    spec_ret = [cast(bool|None, s.rewrite(u)) for s in specs]\n",
    "    if any(ret is False for ret in spec_ret) or all(ret is None for ret in spec_ret):\n",
    "      print_uops(uops)\n",
    "      raise RuntimeError(f\"UOp verification failed at {i} on {u.op} {u.dtype} {len(u.src)} {[x.op for x in u.src]} {u.arg}\")\n",
    "```\n",
    "\n",
    "We combined the extra Pattern Matcher list(s) we get as arguments with [`spec.py:spec`](https://github.com/tinygrad/tinygrad/blob/2d6d8b735506464367b0315f9a2f424e0d19f66e/tinygrad/spec.py#L63).\n",
    "\n",
    "Note that `specs` is a list of PatternMatchers. We don't just combine the Pattern Matchers together (`class PatternMatcher` supports `__add__`), because a Pattern Matcher will ony act on the first match, and we want to check against all specs independently.\n",
    "\n",
    "The rules in the spec return `True`, if the UOp matched a pattern and it was deemed correct, `False` if it matched a deemed incorrect, and as always you get `None` if there was no match:\n",
    "\n",
    "```py\n",
    "spec = PatternMatcher([\n",
    "  (UPat(Ops.DEFINE_GLOBAL, name=\"x\"), lambda x: isinstance(x.dtype, (PtrDType, ImageDType)) and not x.dtype.local),\n",
    "  (UPat(Ops.DEFINE_LOCAL, name=\"x\"), lambda x: isinstance(x.dtype, PtrDType) and x.dtype.local),\n",
    "  ...\n",
    "])\n",
    "```\n",
    "Then, for each UOp we apply each spec one by one. The UOp is correct if\n",
    "- There was a match in at least 1 spec that returned `True`\n",
    "- There was no match with any spec that returned `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.spec import spec, type_verify\n",
    "from tinygrad.tensor import tensor_uop_spec\n",
    "from tinygrad.ops import graph_rewrite_map, merge_views, print_uops\n",
    "from tinygrad.engine.schedule import sym, reorder_view, replace_contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Ops.DEVICE           [None, True]\n",
      "   1 Ops.VIEW             [True, None]\n",
      "   2 Ops.CONST            [True, True]\n",
      "   3 Ops.RESHAPE          [None, True]\n",
      "   4 Ops.EXPAND           [None, True]\n",
      "   5 Ops.PAD              [None, True]\n",
      "   6 Ops.RESHAPE          [None, True]\n",
      "   7 Ops.EXPAND           [None, True]\n",
      "   8 Ops.RESHAPE          [None, True]\n",
      "   9 Ops.SHRINK           [None, True]\n",
      "  10 Ops.RESHAPE          [None, True]\n",
      "  11 Ops.SHRINK           [None, True]\n",
      "  12 Ops.RESHAPE          [None, True]\n",
      "  13 Ops.RESHAPE          [None, True]\n",
      "  14 Ops.PERMUTE          [None, True]\n",
      "  15 Ops.REDUCE_AXIS      [True, None]\n",
      "  16 Ops.RESHAPE          [None, True]\n",
      "  17 Ops.CONST            [True, True]\n",
      "  18 Ops.RESHAPE          [None, True]\n",
      "  19 Ops.EXPAND           [None, True]\n",
      "  20 Ops.ADD              [True, None]\n",
      "  21 Ops.CONST            [True, True]\n",
      "  22 Ops.RESHAPE          [None, True]\n",
      "  23 Ops.EXPAND           [None, True]\n",
      "  24 Ops.ADD              [True, None]\n",
      "  25 Ops.SINK             [True, None]\n"
     ]
    }
   ],
   "source": [
    "for i, u in enumerate(list(big_sink.toposort)):\n",
    "    ret = [s.rewrite(u) for s in (spec, tensor_uop_spec)]\n",
    "    print(f\"{i:4d} {str(u.op):20s} {ret}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, most UOps matched with the tensor spec, some matched with the spec, and a few matched both. No match detected an error.\n",
    "\n",
    "Now to `schedule, var_vals, becomes_map = create_schedule_with_vars(big_sink)` (simplified):\n",
    "\n",
    "```py\n",
    "def create_schedule_with_vars(big_sink:UOp) -> tuple[list[ScheduleItem], dict[Variable, int], dict[UOp, UOp]]:\n",
    "  tensor_map = graph_rewrite_map(big_sink, merge_views+sym+reorder_view+replace_contiguous, ctx={})\n",
    "```\n",
    "\n",
    "graph_rewrite_map, instead of returning a new tree, returns a mapping for each UOp in the original tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx={}\n",
    "\n",
    "tensor_map = graph_rewrite_map(big_sink, merge_views+sym+reorder_view+replace_contiguous, ctx=ctx)\n",
    "\n",
    "# +sym+reorder_view+replace_contiguous\n",
    "\n",
    "# tensor_map = graph_rewrite_map(big_sink, sym+reorder_view+replace_contiguous, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UOp(Ops.RESHAPE, dtypes.float, arg=(1,), src=(\n",
       "  UOp(Ops.CONST, dtypes.float, arg=0.2, src=(\n",
       "    UOp(Ops.VIEW, dtypes.void, arg=ShapeTracker(views=(View(shape=(), strides=(), offset=0, mask=None, contiguous=True),)), src=(\n",
       "      UOp(Ops.DEVICE, dtypes.void, arg='CPU', src=()),)),)),))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(big_sink.get_children_map().keys())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{UOp(Ops.EXPAND, dtypes.float, arg=(8,), src=(\n",
       "   UOp(Ops.RESHAPE, dtypes.float, arg=(1,), src=(\n",
       "     UOp(Ops.CONST, dtypes.float, arg=0.2, src=(\n",
       "       UOp(Ops.VIEW, dtypes.void, arg=ShapeTracker(views=(View(shape=(), strides=(), offset=0, mask=None, contiguous=True),)), src=(\n",
       "         UOp(Ops.DEVICE, dtypes.void, arg='CPU', src=()),)),)),)),)): None}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(big_sink.get_children_map().values())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ops.SINK None: Ops.SINK, [rewritten]\n",
      "Ops.ADD None: Ops.ADD, [rewritten]\n",
      "Ops.EXPAND (8,): Ops.CONST, [rewritten]\n",
      "Ops.RESHAPE (1,): Ops.CONST, [rewritten]\n",
      "Ops.CONST 1.5: Ops.CONST, [same]\n",
      "Ops.ADD None: Ops.ADD, [rewritten]\n",
      "Ops.EXPAND (8,): Ops.CONST, [rewritten]\n",
      "Ops.RESHAPE (1,): Ops.CONST, [rewritten]\n",
      "Ops.CONST 0.3: Ops.CONST, [same]\n",
      "Ops.RESHAPE (8,): Ops.VIEW, [rewritten]\n",
      "Ops.REDUCE_AXIS (<Ops.ADD: 54>, (1,)): Ops.REDUCE_AXIS, [rewritten]\n",
      "Ops.PERMUTE (1, 0): Ops.VIEW, [rewritten]\n",
      "Ops.RESHAPE (8, 8): Ops.VIEW, [rewritten]\n",
      "Ops.RESHAPE (8, 8, 1): Ops.VIEW, [rewritten]\n",
      "Ops.SHRINK ((0, 8), (0, 8)): Ops.VIEW, [rewritten]\n",
      "Ops.RESHAPE (8, 16): Ops.VIEW, [rewritten]\n",
      "Ops.SHRINK ((0, 128),): Ops.VIEW, [rewritten]\n",
      "Ops.RESHAPE (135,): Ops.VIEW, [rewritten]\n",
      "Ops.EXPAND (9, 15): Ops.VIEW, [rewritten]\n",
      "Ops.RESHAPE (1, 15): Ops.VIEW, [rewritten]\n",
      "Ops.PAD ((7, 0),): Ops.VIEW, [rewritten]\n",
      "Ops.EXPAND (8,): Ops.CONST, [rewritten]\n",
      "Ops.RESHAPE (1,): Ops.CONST, [rewritten]\n",
      "Ops.CONST 0.2: Ops.CONST, [same]\n",
      "Ops.VIEW ShapeTracker(views=(View(shape=(), strides=(), offset=0, mask=None, contiguous=True),)): Ops.VIEW, [same]\n",
      "Ops.DEVICE CPU: Ops.DEVICE, [same]\n"
     ]
    }
   ],
   "source": [
    "for k, v in tensor_map.items():\n",
    "    print(f\"{k.op} {k.arg}: {v.op}, {'[same]' if k is v else '[rewritten]'}\")\n",
    "    # print_uops(tuple(v.toposort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ops.SINK -> Ops.SINK\n",
      "Ops.ADD -> Ops.ADD\n",
      "Ops.EXPAND -> Ops.CONST\n",
      "Ops.RESHAPE -> Ops.CONST\n",
      "Ops.CONST -> Ops.CONST\n",
      "Ops.ADD -> Ops.ADD\n",
      "Ops.EXPAND -> Ops.CONST\n",
      "Ops.RESHAPE -> Ops.CONST\n",
      "Ops.CONST -> Ops.CONST\n",
      "Ops.RESHAPE -> Ops.VIEW\n",
      "Ops.REDUCE_AXIS -> Ops.REDUCE_AXIS\n",
      "Ops.PERMUTE -> Ops.VIEW\n",
      "Ops.RESHAPE -> Ops.VIEW\n",
      "Ops.RESHAPE -> Ops.VIEW\n",
      "Ops.SHRINK -> Ops.VIEW\n",
      "Ops.RESHAPE -> Ops.VIEW\n",
      "Ops.SHRINK -> Ops.VIEW\n",
      "Ops.RESHAPE -> Ops.VIEW\n",
      "Ops.EXPAND -> Ops.VIEW\n",
      "Ops.RESHAPE -> Ops.VIEW\n",
      "Ops.PAD -> Ops.VIEW\n",
      "Ops.EXPAND -> Ops.CONST\n",
      "Ops.RESHAPE -> Ops.CONST\n",
      "Ops.CONST -> Ops.CONST\n",
      "Ops.VIEW -> Ops.VIEW\n",
      "Ops.DEVICE -> Ops.DEVICE\n"
     ]
    }
   ],
   "source": [
    "for k, v in tensor_map.items():\n",
    "    print(f\"{k.op} -> {v.op}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "  # get realizes\n",
    "  sink = tensor_map[big_sink]\n",
    "  realize_map = group_realizes(sink)\n",
    "\n",
    "  # merge_views + create_kernels\n",
    "  kernel_map = graph_rewrite_map(sink, merge_views+create_kernels, ctx=KernelContext(realize_map, ops_metadata), bottom_up=True)\n",
    "\n",
    "  sched_sink = kernel_map[sink]\n",
    "\n",
    "  type_verify(list(sched_sink.toposort), kernel_spec)\n",
    "\n",
    "  # map tensors to buffer/const, optionally apply a VIEW on top\n",
    "  becomes_map: dict[UOp, UOp] = {}\n",
    "  for k,v in tensor_map.items():\n",
    "    # ASSIGN always becomes the target buffer\n",
    "    if v.op is Ops.ASSIGN: becomes_map[k] = v.src[0]\n",
    "    # if we created a new buffer for this tensor, map it to the assigned buffer\n",
    "    elif (a:=kernel_map.get(v.base)) is not None and (a:=a.base).op is Ops.ASSIGN:\n",
    "      becomes_map[k] = a.src[0] if a.src[0].st == v.st else a.src[0].view(unwrap(v.st))\n",
    "    # tensors can also simplify to an existing buffer/const\n",
    "    else:\n",
    "      if k is v: continue\n",
    "      if v.base.op is Ops.BUFFER: becomes_map[k] = v\n",
    "      if v.base.op is Ops.CONST and all_int(v.shape): becomes_map[k] = v\n",
    "\n",
    "  # if a kernel depends on a buffer, and that buffer is later assigned to, make the assign depend on the kernel's assign\n",
    "  kernel_assign: dict[UOp, UOp] = {}\n",
    "  assign_rep: dict[UOp, UOp] = {}\n",
    "  for u in sched_sink.toposort:\n",
    "    if u.op is not Ops.ASSIGN: continue\n",
    "    kernel_assign[u.buf_uop] = u\n",
    "    for s in u.src[1].src:\n",
    "      if s.op is not Ops.BUFFER or s is u.buf_uop or (a:=kernel_assign.get(s)) is None: continue\n",
    "      if any(x.op is Ops.ASSIGN and x.buf_uop is s for x in u.toposort):\n",
    "        raise RuntimeError(f\"cycle detected in graph, kernel for {u.buf_uop} must either depend on ASSIGN or BUFFER\")\n",
    "      assign_rep[a] = kernel_assign[s] = a.replace(src=a.src+(u,))\n",
    "  if assign_rep:\n",
    "    sched_sink = sched_sink.substitute(assign_rep)\n",
    "    type_verify(list(sched_sink.toposort), kernel_spec)\n",
    "\n",
    "  # display the final graph\n",
    "  if getenv(\"VIZ\"): graph_rewrite(sched_sink, PatternMatcher([]), name=\"View Kernel Graph\")\n",
    "  if getenv(\"VIZ\"): graph_rewrite(sched_sink, PatternMatcher([]), name=\"View Memory Graph\")\n",
    "\n",
    "  # final toposort (bfs)\n",
    "  children: dict[UOp, list[UOp]] = {}\n",
    "  in_degree: dict[UOp, int] = {}\n",
    "  for u in sched_sink.toposort:\n",
    "    if u.op is not Ops.ASSIGN: continue\n",
    "    in_degree[u] = 0\n",
    "    for s in u.src[1].src:\n",
    "      if s.op is not Ops.ASSIGN: continue\n",
    "      children.setdefault(s, []).append(u)\n",
    "      in_degree[u] += 1\n",
    "\n",
    "  queue = deque(k for k,v in in_degree.items() if v == 0)\n",
    "  schedule: list[ScheduleItem] = []\n",
    "  var_vals: dict[Variable, int] = {}\n",
    "  while queue:\n",
    "    u = queue.popleft()\n",
    "    # TODO: move this to create_kernels\n",
    "    k = fix_kernel_ast(u.src[1], var_vals)\n",
    "    schedule.append(ScheduleItem(k.arg.ast, tuple(s.buf_uop.buffer for s in k.src), k.arg.metadata))\n",
    "    for x in children.get(u, []):\n",
    "      in_degree[x] -= 1\n",
    "      if in_degree[x] == 0: queue.append(x)\n",
    "\n",
    "  # confirm everything was scheduled correctly\n",
    "  if len(schedule) != (kc:=len(in_degree)): raise RuntimeError(f\"cycle detected in graph, created {kc} kernels but only scheduled {len(schedule)}\")\n",
    "  if DEBUG >= 1 and len(schedule) >= 10: print(f\"scheduled {len(schedule)} kernels\")\n",
    "  # capture process replay\n",
    "  if CAPTURE_PROCESS_REPLAY:\n",
    "    with Context(PICKLE_BUFFERS=0): PROCESS_REPLAY_CAPTURE[str(big_sink.key)] = pickle.dumps((big_sink, ContextVar._cache, [x.ast for x in schedule]))\n",
    "  return schedule, var_vals, becomes_map\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
