{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc 1 - elf.py and the ELF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"DEBUG\"] = \"7\"\n",
    "os.environ[\"CACHELEVEL\"] =\"0\"\n",
    "os.environ[\"NOOPT\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELF is the standard format for executables and libraries, as well as intermediate object files (.o) on Linux.\n",
    "\n",
    "TinyGrad uses it for 2 somewhat distinct roles:\n",
    "\n",
    "1. When it generates CPU code (clang or LLVM IR backends), it then needs to load the generated binary code into memory to run it.\n",
    "\n",
    "> We could have built a shared library (.so), but then I think we'd have to save it to use `dlopen()`, and it would not be portable anyway. So instead of this, TinyGrad only does the compilation step (generates a .o) and implements a minimal ELF loader.\n",
    "\n",
    "> [@uuuuvn](https://github.com/uuuvn) also pointed out that doing a proper linking step is slow, and there is a bug in the OSX linker that can't output to stdout.\n",
    "\n",
    "2. When it generates cuda code, it also comes out as ELF. The sections and relocation rules are different from those found on Linux, but the format is the same.\n",
    "\n",
    "> The CUDA Runtime library would be able to load this object file, and that's what we do for the `CUDA` backend, but the `NV` backend does not rely on the CUDA Runtime libraries, so we parse the ELF manually.\n",
    "\n",
    "The loader and relocation code for host (x86_64 and ARM 64) platforms is implemented in [tinygrad/runtime/support/elf.py](https://github.com/tinygrad/tinygrad/blob/09ec33a5786cd59cb013dd736250fa58a56203d5/tinygrad/runtime/support/elf.py)\n",
    "\n",
    "Since we only deal with self-contained object files (they don't access data/function from other files), the task is less danting than you might thnk.\n",
    "\n",
    "Let's first look at the ELF format, at least the bits relevant here:\n",
    "\n",
    "### ELF format\n",
    "#### ELF Header (`Elf64_Ehdr`)\n",
    "*   Located at the very beginning of the file.\n",
    "*   Contains essential metadata:\n",
    "    *   `e_ident`: Magic number (`\\x7fELF`) and info like 64-bit (`ELFCLASS64`), endianness (`ELFDATA2LSB`), OS ABI.\n",
    "    *   `e_type`: File type (e.g., `ET_REL` for relocatable/object file, `ET_EXEC` for executable, `ET_DYN` for shared object). `elf.py` expects `ET_REL`.\n",
    "    *   `e_machine`: Target architecture (e.g., `EM_X86_64`, `EM_AARCH64`).\n",
    "    *   `e_shoff`: Offset to the Section Header Table.\n",
    "    *   `e_shnum`: Number of entries in the Section Header Table.\n",
    "    *   `e_shstrndx`: Index of the section header table entry that contains section names.\n",
    "\n",
    "#### Section Header Table:\n",
    "*   An array of `Elf64_Shdr` structures.\n",
    "*   Each entry describes a *section* in the file.\n",
    "*   Key `Elf64_Shdr` fields used by `elf.py`:\n",
    "    *   `sh_name`: Offset into the Section Name String Table (`.shstrtab`) for this section's name.\n",
    "    *   `sh_type`: Type of section (e.g., `SHT_PROGBITS` for code/data, `SHT_SYMTAB` for symbols, `SHT_RELA`/`SHT_REL` for relocations, `SHT_STRTAB` for strings, `SHT_NOBITS` for `.bss`).\n",
    "    *   `sh_flags`: Attributes like `SHF_ALLOC` (load into memory), `SHF_WRITE`, `SHF_EXECINSTR`.\n",
    "    *   `sh_addr`: The *intended* virtual memory address during execution. For `.o` files (type `ET_REL`), this is often 0 for most sections, as the final address isn't known yet. `elf.py` updates this for sections it places.\n",
    "    *   `sh_offset`: Offset of the section's content within the ELF file itself.\n",
    "    *   `sh_size`: Size of the section's content in the file (or memory size for `SHT_NOBITS`).\n",
    "    *   `sh_link`, `sh_info`: Used by specific section types (e.g., `.symtab` uses `sh_link` to point to its string table).\n",
    "    *   `sh_addralign`: Required alignment constraint for the section's start address.\n",
    "    *   `sh_entsize`: Size of each entry if the section holds a table (like symbol table or relocation table).\n",
    "\n",
    "#### Sections:\n",
    "*   Contiguous chunks of bytes (or just metadata for `SHT_NOBITS`) described by the Section Header Table.\n",
    "*   Common sections relevant here:\n",
    "    *   `.text`: Executable code (`SHT_PROGBITS`).\n",
    "    *   `.data`: Initialized global/static variables (`SHT_PROGBITS`).\n",
    "    *   `.rodata`: Read-only data (constants, strings) (`SHT_PROGBITS`).\n",
    "    *   `.bss`: Uninitialized global/static variables (`SHT_NOBITS`). Occupies no space in the file but needs space allocated in memory. (`elf.py` doesn't explicitly handle `.bss` size allocation based on `sh_size`, it only lays out `SHT_PROGBITS`).\n",
    "    *   `.symtab`: Symbol Table (`SHT_SYMTAB`). Lists defined and referenced symbols (functions, variables).\n",
    "    *   `.strtab`: String Table (`SHT_STRTAB`). Stores names for symbols.\n",
    "    *   `.shstrtab`: Section Header String Table (`SHT_STRTAB`). Stores names for sections.\n",
    "    *   `.rela.text`, `.rel.text`, etc.: Relocation sections (`SHT_RELA`, `SHT_REL`). Contain instructions for patching code/data.\n",
    "\n",
    "### Relocations\n",
    "Even for a self-contained file, the compiler generates an object file with symbols (constants, global vars, functions) that don't have their final location assigned.\n",
    "This code might:\n",
    "\n",
    "- Access a function defined elsewhere in the same file (e.g., a helper function in another part of `.text`).\n",
    "- Reference constants or static data (e.g., accessing a string literal in `.rodata` or a static array in `.data`).\n",
    "\n",
    "> When generating CPU code, PC-relative addressing are used, so the code does not care where it will be placed in memory for execution. Still, the code will refernce stuff in .rodata, so it needs to know the address. \n",
    "\n",
    "TinyGrad (at least for now) does not generate code with subroutines or global variables, which makes out task easier.\n",
    "\n",
    "Relocations are metadata entries that tell our loader how to patch the machine code once we've determined where each section will be placed in memory. For self-contained files, we only need to resolve references within the same object file, not external dependencies.\n",
    "\n",
    "\n",
    "There are 2 types of relocation entries, `REL` and `RELA`:\n",
    "\n",
    "- For rel, the instruction will contain the address of relative to Program Counter (PC), so we will read this address, add the offset, and patch the instruction.\n",
    "- For rela, the instruction contains zeros (or any value really) for the address, and the rela entry contains the address. We add offset to it, and rewrite the value from the instruction.\n",
    "\n",
    "#### Relocation Sections:\n",
    "\n",
    "-   Contain arrays of relocation entries.\n",
    "-   The section name indicates which *other* section the relocations apply to (e.g., `.rela.text` contains patches for the `.text` section). `elf.py` uses `sh.name[5:]` or `sh.name[4:]` to find the target section name.\n",
    "-   There are two main types:\n",
    "    -   `SHT_RELA`: Entries contain an *explicit addend*. (`Elf64_Rela`)\n",
    "    -   `SHT_REL`: Entries have an *implicit addend* (usually the value already present at the location being patched). (`Elf64_Rel`)\n",
    "\n",
    "#### Relocation Entries (`Elf64_Rela` / `Elf64_Rel`):\n",
    "Each entry describes a single patch. Key fields:\n",
    "\n",
    "-   `r_offset`: The offset *within the target section* where the patch needs to be applied. Let's call the final address `P = section_base + r_offset`.\n",
    "-   `r_info`: A combined field containing:\n",
    "    -   **Symbol Index (`ELF64_R_SYM(r_info)`):** An index into the `.symtab` section. This identifies the symbol whose address is needed for the calculation. Let the symbol's final address be `S`.\n",
    "    -   **Relocation Type (`ELF64_R_TYPE(r_info)`):** Specifies *how* to calculate the value to be patched and *how* to insert it at `P`. This is architecture-specific. Examples:\n",
    "        - For X86_64, we only support `R_X86_64_PC32`, calculate `S + A - P` (Symbol + Addend - PatchLocation) and store the 32-bit result.\n",
    "        - For ARM 64, we have more options, and we actually have to patch some bits in the target instruction. \n",
    "-   `r_addend` (`Elf64_Rela` only): An explicit constant value (`A`) to be used in the relocation calculation (e.g., `S + A - P`). For `Elf64_Rel`, the addend `A` is implicitly the value already stored in the instruction/data at `P` before patching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running code on CPU\n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "`elftest.c`\n",
      "\n",
      "::: {.sourceCode}\n",
      "```cpp\n",
      "float foo(int x) { return x + 12345678.f; } // I use float because an int const stays in .text for some reason\n",
      "```\n",
      ":::\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|output: asis\n",
    "#|echo: false\n",
    "\n",
    "from pathlib import Path\n",
    "c_code = Path(\"elftest.c\").read_text()\n",
    "print(f'''\n",
    "`elftest.c`\n",
    "\n",
    "::: {{.sourceCode}}\n",
    "```cpp\n",
    "{c_code}\n",
    "```\n",
    ":::\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!clang -c -x c -march=native --target=x86_64-none-unknown-elf -O0 -fPIC \\\n",
    "    -ffreestanding -fno-math-errno -fno-ident -nostdlib elftest.c -o elftest.o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "elftest.o:     file format elf64-x86-64\n",
      "\n",
      "RELOCATION RECORDS FOR [.text]:\n",
      "OFFSET           TYPE              VALUE\n",
      "0000000000000010 R_X86_64_PC32     .LCPI0_0-0x0000000000000004\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!objdump -r elftest.o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a single relocation entry, it's for that float constant that went onto .rodata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "elftest.o:     file format elf64-x86-64\n",
      "\n",
      "\n",
      "Disassembly of section .text:\n",
      "\n",
      "0000000000000000 <foo>:\n",
      "   0:\t55                   \tpush   %rbp\n",
      "   1:\t48 89 e5             \tmov    %rsp,%rbp\n",
      "   4:\t89 7d fc             \tmov    %edi,-0x4(%rbp)\n",
      "   7:\tc5 fa 2a 45 fc       \tvcvtsi2ssl -0x4(%rbp),%xmm0,%xmm0\n",
      "   c:\tc5 fa 10 0d 00 00 00 \tvmovss 0x0(%rip),%xmm1        # 14 <foo+0x14>\n",
      "  13:\t00 \n",
      "  14:\tc5 fa 58 c1          \tvaddss %xmm1,%xmm0,%xmm0\n",
      "  18:\t5d                   \tpop    %rbp\n",
      "  19:\tc3                   \tret\n"
     ]
    }
   ],
   "source": [
    "!objdump -d elftest.o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see for that `vmovss` instruction, the address part is currently `00 00 00 00`. The address part is located at `0x10`, which matches the offset in the relocation table.\n",
    "\n",
    "Let's look at the `.rodata.cst4` section. The `.cst4` means this .rodata sectoin is for 4-byte constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "elftest.o:     file format elf64-x86-64\n",
      "\n",
      "Contents of section .rodata.cst4:\n",
      " 0000 4e613c4b                             Na<K            \n"
     ]
    }
   ],
   "source": [
    "!objdump -s -j .rodata.cst4 elftest.o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must be the float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x4b3c614e'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "hex(np.float32(12345678.).view(np.uint32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes it is.\n",
    "\n",
    "The bytes are in reverse order because x86 is a little-endian architecture.\n",
    "\n",
    "Let's load it with elf_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.runtime.support.elf import elf_loader, relocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 32 bytes\n",
      "\n",
      "Sections:\n",
      "  0:  (size: 0, addr: 0x0)\n",
      "  1: .strtab (size: 94, addr: 0x0)\n",
      "  2: .text (size: 26, addr: 0x0)\n",
      "  3: .rela.text (size: 24, addr: 0x0)\n",
      "  4: .rodata.cst4 (size: 4, addr: 0x1c)\n",
      "  5: .note.GNU-stack (size: 0, addr: 0x20)\n",
      "  6: .llvm_addrsig (size: 0, addr: 0x0)\n",
      "  7: .symtab (size: 96, addr: 0x0)\n",
      "\n",
      "Relocations:\n",
      "  0: offset=0x10, target=0x1c, type=2, addend=-4\n"
     ]
    }
   ],
   "source": [
    "with open('elftest.o', 'rb') as f:\n",
    "    elf_bytes = f.read()\n",
    "\n",
    "image, sections, relocs = elf_loader(elf_bytes)\n",
    "\n",
    "print(f\"Image size: {len(image)} bytes\")\n",
    "print(\"\\nSections:\")\n",
    "for i, section in enumerate(sections):\n",
    "    print(f\"  {i}: {section.name} (size: {section.header.sh_size}, addr: {hex(section.header.sh_addr)})\")\n",
    "\n",
    "if relocs:\n",
    "    print(\"\\nRelocations:\")\n",
    "    for i, (offset, target, r_type, addend) in enumerate(relocs):\n",
    "        print(f\"  {i}: offset={hex(offset)}, target={hex(target)}, type={r_type}, addend={addend}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disassemble the code in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x000000: push\trbp\n",
      "0x000001: mov\trbp, rsp\n",
      "0x000004: mov\tdword ptr [rbp - 4], edi\n",
      "0x000007: vcvtsi2ss\txmm0, xmm0, dword ptr [rbp - 4]\n",
      "0x00000c: vmovss\txmm1, dword ptr [rip]\n",
      "0x000014: vaddss\txmm0, xmm0, xmm1\n",
      "0x000018: pop\trbp\n",
      "0x000019: ret\t\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.helpers import capstone_flatdump\n",
    "\n",
    "capstone_flatdump(image[:0x1a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .rodata was added jught after .text (with 2 bytes to align it on a 4-byte boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4e613c4b'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0x1c:0x20].hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the relocations. This is pretty much what `elf.py:jit_loader` does.\n",
    "\n",
    "> Note: `jit_loader` is not directly related to `TinyJit`, JIT is an overloaded term, and we compile the kernels ... just in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relocating at address 0x10, PC at 0x14\n",
      "Before: 0x00000000\n",
      "After:  0x08000000\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "for ploc,tgt,r_type,r_addend in relocs:\n",
    "    print(f\"Relocating at address {hex(ploc)}, PC at {hex(ploc+4)}\")\n",
    "    print(f\"Before: 0x{image[ploc:ploc+4].hex()}\")\n",
    "    image[ploc:ploc+4] = struct.pack(\"<I\", relocate(struct.unpack(\"<I\", image[ploc:ploc+4])[0], ploc, tgt+r_addend, r_type))\n",
    "    print(f\"After:  0x{image[ploc:ploc+4].hex()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `0x08000000` is actually just 8, keep the endianess in mind. While we are patching at address 0x10, the PC must be at the next instruction already, 0x14, skipping the 4 byes of `00 00 00 00`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x1c'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(0x14 + 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is indeed the address of the constant. Now, let's run the code. This is normally done in `device.py:CPUProgram.__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12345999.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinygrad.helpers import mv_address\n",
    "from tinygrad.device import CPUProgram\n",
    "import ctypes\n",
    "from mmap import mmap, PROT_READ, PROT_WRITE, PROT_EXEC, MAP_ANON, MAP_PRIVATE\n",
    "\n",
    "mem = mmap(-1, len(image), MAP_ANON | MAP_PRIVATE, PROT_READ | PROT_WRITE | PROT_EXEC)\n",
    "mem.write(image)\n",
    "\n",
    "CPUProgram.rt_lib[\"__clear_cache\"](ctypes.c_void_p(mv_address(mem)), ctypes.c_void_p(mv_address(mem) + len(image)))\n",
    "\n",
    "fxn = ctypes.CFUNCTYPE(ctypes.c_float)(mv_address(mem))\n",
    "\n",
    "# CPUProgram.__call__\n",
    "fxn(ctypes.c_int32(321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Allocate a piece of memory, and make it executable. We can't just mark our image as executable, because the flags are applied to memory pages (4096 bytes), and our image is not aligned to page boundary.\n",
    "- Copy the image (lib) into that memory.\n",
    "- Clear instruction cache. I'm not entirely sure how the instruction cache works on different architectures, I guess it might be required at least on some architecures. Skipping this step did not cause issues for me.\n",
    "- Wrap it in a python function using `ctypes` and call it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NV backend\n",
    "\n",
    "Now, we also use the same loader with the `NV` backend without relying on the CUDA Runtime library to load it. Let's take a look at `ops_nv.py:NVProgram`\n",
    "```py\n",
    "    image, sections, relocs = elf_loader(self.lib, force_section_align=128)\n",
    "    self.lib_gpu = self.dev.allocator.alloc(round_up(image.nbytes, 0x1000) + 0x1000, BufferSpec(cpu_access=True))\n",
    "```\n",
    "Load the elf and allocate a buffer on the GPU.\n",
    "\n",
    "> Note: We use the CUDA Unified Memory, so the buffer is mapped at the same vitual address on both the host and the GPU.\n",
    "> I did not know this was even possible.\n",
    "\n",
    "```py\n",
    "    self.prog_addr, self.prog_sz, self.regs_usage, self.shmem_usage, self.lcmem_usage = self.lib_gpu.va_addr, image.nbytes, 0, 0x400, 0\n",
    "    self.constbufs: dict[int, tuple[int, int]] = {0: (0, 0x160)} # dict[constbuf index, tuple[va_addr, size]]\n",
    "    for sh in sections:\n",
    "      if sh.name == f\".nv.shared.{self.name}\": self.shmem_usage = round_up(0x400 + sh.header.sh_size, 128)\n",
    "      if sh.name == f\".text.{self.name}\":\n",
    "        self.prog_addr, self.prog_sz, self.regs_usage = self.lib_gpu.va_addr+sh.header.sh_addr, sh.header.sh_size, max(sh.header.sh_info>>24, 16)\n",
    "      elif m:=re.match(r'\\.nv\\.constant(\\d+)', sh.name): self.constbufs[int(m.group(1))] = (self.lib_gpu.va_addr+sh.header.sh_addr, sh.header.sh_size)\n",
    "      elif sh.name.startswith(\".nv.info\"):\n",
    "        for typ, param, data in self._parse_elf_info(sh):\n",
    "          if sh.name == f\".nv.info.{name}\" and param == 0xa: cbuf0_size = struct.unpack_from(\"IH\", data)[1] # EIATTR_PARAM_CBANK\n",
    "          elif sh.name == \".nv.info\" and param == 0x12: self.lcmem_usage = struct.unpack_from(\"II\", data)[1] + 0x240 # EIATTR_MIN_STACK_SIZE\n",
    "```\n",
    "Extract information from the Nvidia-specific headers, like the size of shared memory, registers, etc, used by the kernel.\n",
    "\n",
    "```py\n",
    "    for apply_image_offset, rel_sym_offset, typ, _ in relocs:\n",
    "      # These types are CUDA-specific, applying them here\n",
    "      if typ == 2: image[apply_image_offset:apply_image_offset+8] = struct.pack('<Q', self.lib_gpu.va_addr + rel_sym_offset) # R_CUDA_64\n",
    "      elif typ == 0x38: image[apply_image_offset+4:apply_image_offset+8] = struct.pack('<I', (self.lib_gpu.va_addr + rel_sym_offset) & 0xffffffff)\n",
    "      elif typ == 0x39: image[apply_image_offset+4:apply_image_offset+8] = struct.pack('<I', (self.lib_gpu.va_addr + rel_sym_offset) >> 32)\n",
    "      else: raise RuntimeError(f\"unknown NV reloc {typ}\")\n",
    "```\n",
    "Apply relocations. Nvidia has its own types of relocations for different addressing modes on GPU.\n",
    "\n",
    "> Note that `va_addr` is valid on both the host and the GPU.\n",
    "\n",
    "```py\n",
    "    ctypes.memmove(self.lib_gpu.va_addr, mv_address(image), image.nbytes)\n",
    "```\n",
    "Copy the relocated image into the buffer.\n",
    "\n",
    "A bit more Nvidia magic needs to happen to kick off the execution, but you get the idea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
