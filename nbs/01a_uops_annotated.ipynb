{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - UOp Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "UOps form the intermediate representation (IR) in tinygrad's computation graph *after* the initial Tensor operations are defined and *before* final code generation. They represent a lower-level, more explicit graph that undergoes several optimization and transformation passes.\n",
    "\n",
    "---\n",
    "\n",
    "### Meta / Framework Ops\n",
    "\n",
    "These UOps are primarily used by the tinygrad framework itself for graph structure, scheduling, device management, and metadata, rather than direct computation on tensor data.\n",
    "\n",
    "#### `SINK`\n",
    "*   **Description:** Represents the final output(s) of a computation graph or kernel. It acts as a root node for graph traversal and scheduling.\n",
    "*   **Purpose:** Marks the end of a computation path that needs to be realized. Used to define the boundaries of kernels during scheduling.\n",
    "*   **Args:** Optional `KernelInfo` containing metadata about the kernel (name, local dims, etc.).\n",
    "*   **Sources:** One or more UOps that produce the final results (often `STORE` or `ASSIGN` ops).\n",
    "*   **Stage:** Graph Construction, Scheduling (marks kernel boundaries).\n",
    "*   **Notes:** Essential for defining what needs to be computed. Multiple UOps can feed into a single `SINK`. Simplified away before final rendering.\n",
    "\n",
    "#### `KERNEL`\n",
    "*   **Description:** An internal UOp used during scheduling to encapsulate the operations belonging to a single kernel launch.\n",
    "*   **Purpose:** Groups UOps together that will be executed as one unit on the target device. Helps manage kernel boundaries and dependencies.\n",
    "*   **Args:** `Kernel` object containing the kernel's AST and metadata.\n",
    "*   **Sources:** UOps representing the inputs required by the kernel (often `BUFFER` or other `KERNEL` outputs via `ASSIGN`).\n",
    "*   **Stage:** Scheduling.\n",
    "*   **Notes:** This is a temporary node used by the scheduler and is expanded/replaced before final code generation.\n",
    "\n",
    "#### `NAME`\n",
    "*   **Description:** Assigns a name (string) to a UOp, typically used for naming kernels or variables in the generated code.\n",
    "*   **Purpose:** Code readability and debugging. Allows generated kernels/variables to have meaningful names based on the high-level operations.\n",
    "*   **Args:** `str` - the desired name.\n",
    "*   **Sources:** Usually none, but can wrap other ops during specific transformations.\n",
    "*   **Stage:** Scheduling, Code Generation.\n",
    "*   **Notes:** Often associated with `SINK` or `DEFINE_VAR`.\n",
    "\n",
    "#### `DEVICE`\n",
    "*   **Description:** Represents a target device (e.g., \"CPU\", \"CUDA:0\").\n",
    "*   **Purpose:** Specifies the device for memory allocation or computation. Used as a source for `BUFFER`, `COPY`, `CONST`.\n",
    "*   **Args:** `str` - the device name.\n",
    "*   **Sources:** None.\n",
    "*   **Stage:** Graph Construction, Scheduling.\n",
    "\n",
    "#### `MULTI`\n",
    "*   **Description:** Represents a tensor sharded across multiple devices.\n",
    "*   **Purpose:** Manages data parallelism by holding references to UOps representing shards on different devices.\n",
    "*   **Args:** `(Optional[int], tuple[bool, ...])` - The sharding axis (or `None`) and a tuple indicating which shards hold real data (vs padding/zeros).\n",
    "*   **Sources:** Multiple UOps, each representing a shard on a specific device.\n",
    "*   **Stage:** Graph Construction (created by `Tensor.shard`).\n",
    "*   **Notes:** Handled by a specific rewrite pass (`get_multi_map`) to distribute operations across shards.\n",
    "\n",
    "#### `COPY`\n",
    "*   **Description:** Copies data from one buffer/device to another.\n",
    "*   **Purpose:** Explicit data movement between devices or cloning a buffer.\n",
    "*   **Args:** `bool` - `clone=True` forces a new allocation even on the same device.\n",
    "*   **Sources:** `(DEVICE, UOp)` - Target device and the UOp to copy from.\n",
    "*   **Stage:** Graph Construction, Scheduling.\n",
    "*   **Notes:** Simplified away if source and destination devices are the same and `clone=False`. Can become `BufferXfer` for optimized transfers.\n",
    "\n",
    "#### `ASSIGN`\n",
    "*   **Description:** Represents an assignment operation. At the Tensor level, it signifies `tensor.assign(other_tensor)`. At the UOp level after lowering, it often represents updating an accumulator (`DEFINE_ACC`).\n",
    "*   **Purpose:** In-place modification of data (conceptually) or accumulator updates.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(target, value)` - The UOp being assigned to (often `BUFFER` or `DEFINE_ACC`) and the new value UOp.\n",
    "*   **Stage:** Graph Construction, Lowering (Accumulator updates).\n",
    "*   **Notes:** High-level `ASSIGN` is often lowered to `STORE` or kernel operations. Low-level `ASSIGN` is crucial for reductions.\n",
    "\n",
    "#### `BIND`\n",
    "*   **Description:** Binds a symbolic `Variable` (`DEFINE_VAR`) to a concrete integer value (`CONST`).\n",
    "*   **Purpose:** Resolves symbolic dimensions or parameters at runtime or during JIT compilation.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(DEFINE_VAR, CONST)` - The variable and the constant value it's bound to.\n",
    "*   **Stage:** Graph Construction (Symbolic Shapes), JIT.\n",
    "*   **Notes:** Removed during scheduling/lowering by substituting the variable with its bound constant value.\n",
    "\n",
    "#### `DEFINE_VAR`\n",
    "*   **Description:** Defines a symbolic variable, typically representing a dimension size.\n",
    "*   **Purpose:** Allows for operations on tensors with shapes that are not known at compile time (symbolic shapes).\n",
    "*   **Args:** `(name: str, min_val: int, max_val: int)` - Name and range of the variable.\n",
    "*   **Sources:** None.\n",
    "*   **Stage:** Graph Construction (Symbolic Shapes).\n",
    "*   **Notes:** Usually bound using `BIND` before execution.\n",
    "\n",
    "#### `UNIQUE`\n",
    "*   **Description:** Represents a unique identifier, typically used for buffer allocation.\n",
    "*   **Purpose:** Ensures that different `BUFFER` UOps representing distinct allocations get unique identities, even if they have the same size/dtype/device.\n",
    "*   **Args:** `int` - A unique integer.\n",
    "*   **Sources:** None.\n",
    "*   **Stage:** Graph Construction (Buffer creation).\n",
    "\n",
    "#### `EMPTY`\n",
    "*   **Description:** Represents an empty tensor (placeholder).\n",
    "*   **Purpose:** Used internally, often as a starting point for tensor creation before data is specified (e.g., `Tensor.empty`).\n",
    "*   **Args:** None.\n",
    "*   **Sources:** None.\n",
    "*   **Stage:** Graph Construction.\n",
    "*   **Notes:** Usually replaced or filled quickly.\n",
    "\n",
    "#### `NOOP`\n",
    "*   **Description:** A no-operation instruction.\n",
    "*   **Purpose:** Used as a placeholder or identity operation during graph transformations, often inserted and then removed by subsequent passes. Can sometimes force materialization in specific backends (e.g., before `BITCAST`).\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(UOp,)` - The UOp to pass through.\n",
    "*   **Stage:** Intermediate Transformations.\n",
    "\n",
    "#### `CUSTOM` / `CUSTOMI`\n",
    "*   **Description:** Represents a custom operation defined by a string, potentially with specific backend implementations. `CUSTOMI` implies inline code.\n",
    "*   **Purpose:** Allows extending tinygrad with operations not covered by standard Ops, often for backend-specific intrinsics or complex fused operations.\n",
    "*   **Args:** `str` - A format string for the custom code.\n",
    "*   **Sources:** Variable number of UOps, used to fill the format string.\n",
    "*   **Stage:** Lowering, Code Generation.\n",
    "\n",
    "---\n",
    "\n",
    "### Constants\n",
    "\n",
    "#### `CONST`\n",
    "*   **Description:** Represents a scalar constant value.\n",
    "*   **Purpose:** Embeds constant values directly into the computation graph.\n",
    "*   **Args:** `ConstType` (int, float, bool) - The constant value.\n",
    "*   **Sources:** Usually none, but can have a `VIEW(DEVICE)` source to indicate device placement.\n",
    "*   **Stage:** All stages.\n",
    "*   **Notes:** `Tensor.full` creates `CONST` ops expanded to the correct shape.\n",
    "\n",
    "#### `VCONST`\n",
    "*   **Description:** Represents a vector constant value.\n",
    "*   **Purpose:** Similar to `CONST` but for vector types.\n",
    "*   **Args:** `tuple[ConstType, ...]` - The tuple of constant values.\n",
    "*   **Sources:** Usually none.\n",
    "*   **Stage:** All stages.\n",
    "*   **Notes:** Often lowered to `VECTORIZE(CONST, CONST, ...)` during rendering.\n",
    "\n",
    "---\n",
    "\n",
    "### Movement Ops\n",
    "\n",
    "These ops change the logical view (shape, strides, offset, mask) of data without necessarily moving or copying it in memory immediately. They primarily manipulate the `ShapeTracker` associated with a buffer.\n",
    "\n",
    "#### `RESHAPE`\n",
    "*   **Description:** Changes the shape of the tensor while preserving the total number of elements.\n",
    "*   **Purpose:** Modifies the logical dimensions.\n",
    "*   **Args:** `tuple[sint, ...]` - The new shape.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** High-level, Lowering.\n",
    "*   **Notes:** Lowered into `VIEW` ops.\n",
    "\n",
    "#### `PERMUTE`\n",
    "*   **Description:** Reorders the dimensions of the tensor.\n",
    "*   **Purpose:** Changes the logical order of axes.\n",
    "*   **Args:** `tuple[int, ...]` - The permutation order.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** High-level, Lowering.\n",
    "*   **Notes:** Lowered into `VIEW` ops.\n",
    "\n",
    "#### `EXPAND`\n",
    "*   **Description:** Expands dimensions of size 1 to a larger size.\n",
    "*   **Purpose:** Broadcasting.\n",
    "*   **Args:** `tuple[sint, ...]` - The target shape with expanded dimensions.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** High-level, Lowering.\n",
    "*   **Notes:** Lowered into `VIEW` ops. Stride becomes 0 for expanded dimensions.\n",
    "\n",
    "#### `PAD`\n",
    "*   **Description:** Adds padding to the tensor along specified dimensions.\n",
    "*   **Purpose:** Increases the size of dimensions, typically for convolutions or alignment.\n",
    "*   **Args:** `tuple[tuple[sint, sint], ...]` - Padding amounts (before, after) for each dimension.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** High-level, Lowering.\n",
    "*   **Notes:** Lowered into `VIEW` ops. Adjusts offset and mask.\n",
    "\n",
    "#### `SHRINK`\n",
    "*   **Description:** Shrinks the tensor along specified dimensions by selecting a sub-region.\n",
    "*   **Purpose:** Cropping or selecting parts of a tensor.\n",
    "*   **Args:** `tuple[tuple[sint, sint], ...]` - Start and end indices (exclusive) for shrinking each dimension.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** High-level, Lowering.\n",
    "*   **Notes:** Lowered into `VIEW` ops. Adjusts offset and mask.\n",
    "\n",
    "#### `FLIP`\n",
    "*   **Description:** Reverses the order of elements along specified dimensions.\n",
    "*   **Purpose:** Data augmentation or specific algorithms requiring reversed views.\n",
    "*   **Args:** `tuple[bool, ...]` - A boolean tuple indicating which axes to flip.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** High-level, Lowering.\n",
    "*   **Notes:** Lowered into `VIEW` ops. Modifies strides and offset.\n",
    "\n",
    "---\n",
    "\n",
    "### Lowering / Indexing Ops\n",
    "\n",
    "These UOps appear during the lowering process, translating logical views and operations into memory accesses and validity checks.\n",
    "\n",
    "#### `VIEW`\n",
    "*   **Description:** Represents a logical view (`ShapeTracker`) applied to a base buffer UOp. This is the primary way movement ops are represented after initial lowering.\n",
    "*   **Purpose:** Encapsulates shape, stride, offset, and mask information without creating new data. Connects logical tensor operations to underlying buffer representations.\n",
    "*   **Args:** `ShapeTracker` - The view information.\n",
    "*   **Sources:** `(UOp,)` - The base UOp (often `BUFFER`, `CONST`, or another `VIEW`). Can also have a `DEVICE` source for `CONST`.\n",
    "*   **Stage:** Lowering, Scheduling.\n",
    "*   **Notes:** Multiple `VIEW` ops are merged into one. `CONTIGUOUS` ops often trigger realization before a `VIEW`. `VIEW` ops are pushed towards memory operations (`LOAD`/`STORE`) or constants during simplification.\n",
    "\n",
    "#### `INDEX`\n",
    "*   **Description:** Calculates a memory address/index based on a buffer and logical indices, potentially applying a validity mask.\n",
    "*   **Purpose:** Translates multi-dimensional logical indexing into a linear memory index for `LOAD` and `STORE`. Encapsulates the `ShapeTracker.to_indexed_uops` logic.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(buffer_uop, logical_indices_uop, Optional[valid_uop])` - The buffer (e.g., `DEFINE_GLOBAL`), the calculated index expression, and an optional validity mask (`dtypes.bool`).\n",
    "*   **Stage:** Lowering (post `rewrite_shapetracker_with_index`), Codegen.\n",
    "*   **Notes:** This is part of the \"new style\" load/store introduced to simplify rendering.\n",
    "\n",
    "#### `VALID`\n",
    "*   **Description:** Represents the validity mask derived from a `ShapeTracker`'s mask attribute.\n",
    "*   **Purpose:** Computes whether a given logical index corresponds to a valid element within the original (unpadded, unshrunk) data. Used for masking operations, especially loads/stores near boundaries.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(VIEW,)` - The `VIEW` UOp containing the `ShapeTracker` with mask information.\n",
    "*   **Stage:** Lowering.\n",
    "*   **Notes:** Often simplified or combined with index calculations. Becomes the `valid` part of `INDEX` or the gate in `LOAD`/`STORE`.\n",
    "\n",
    "#### `GEP` (Get Element Pointer)\n",
    "*   **Description:** Extracts specific elements from a vector UOp.\n",
    "*   **Purpose:** Accessing individual lanes of a vectorized operation or constant.\n",
    "*   **Args:** `tuple[int, ...]` - The indices of the elements to extract.\n",
    "*   **Sources:** `(UOp,)` - The vector UOp.\n",
    "*   **Stage:** Codegen, Final Rendering.\n",
    "*   **Notes:** The inverse of `VECTORIZE`. Allows scalar operations on elements previously combined into a vector.\n",
    "\n",
    "---\n",
    "\n",
    "### Memory Ops\n",
    "\n",
    "These UOps deal directly with memory allocation, definition, and access.\n",
    "\n",
    "#### `BUFFER`\n",
    "*   **Description:** Represents a raw memory buffer allocated on a specific device. This is the \"base\" UOp for most tensor data after initial allocation.\n",
    "*   **Purpose:** Holds the reference to the actual allocated memory used by tensors.\n",
    "*   **Args:** `int` - Size of the buffer in elements.\n",
    "*   **Sources:** `(DEVICE, UNIQUE)` - The device and a unique identifier.\n",
    "*   **Stage:** Graph Construction, Scheduling.\n",
    "*   **Notes:** `BUFFER` UOps map to `Buffer` objects which manage the actual memory. `BUFFER` itself doesn't have a `ShapeTracker`; `VIEW` ops are applied on top.\n",
    "\n",
    "#### `BUFFER_VIEW`\n",
    "*   **Description:** Represents a view of an existing `BUFFER` UOp, potentially with an offset. Introduced for DISK buffers.\n",
    "*   **Purpose:** Allows accessing parts of a larger buffer (e.g., a file on disk) without loading the entire thing.\n",
    "*   **Args:** `(size: int, offset: int)` - Size in elements and offset in elements from the base buffer.\n",
    "*   **Sources:** `(BUFFER,)` - The base buffer.\n",
    "*   **Stage:** Scheduling (Specific backends like DISK).\n",
    "\n",
    "#### `DEFINE_GLOBAL`\n",
    "*   **Description:** Defines a global buffer in the kernel arguments.\n",
    "*   **Purpose:** Declares input/output buffers passed into the kernel.\n",
    "*   **Args:** `int` (optional, buffer index) or `None`.\n",
    "*   **Sources:** None.\n",
    "*   **Stage:** Final Lowering (inside `linearize_uop`), Codegen.\n",
    "*   **Notes:** Has a `PtrDType`. The renderer uses this to generate kernel signatures.\n",
    "\n",
    "#### `DEFINE_LOCAL`\n",
    "*   **Description:** Defines a buffer in local (shared) memory.\n",
    "*   **Purpose:** Allocation of shared memory for intermediate results accessible by threads within a workgroup.\n",
    "*   **Args:** `str` - Name for the local buffer.\n",
    "*   **Sources:** None.\n",
    "*   **Stage:** Lowering, Codegen.\n",
    "*   **Notes:** Has a `PtrDType` with `local=True`. Requires synchronization (`BARRIER`).\n",
    "\n",
    "#### `DEFINE_ACC`\n",
    "*   **Description:** Defines an accumulator register or variable, typically initialized to an identity element and used within reduction loops.\n",
    "*   **Purpose:** Holds the intermediate state during reduction operations.\n",
    "*   **Args:** `(int,)` - An accumulator index/identifier.\n",
    "*   **Sources:** `(initial_value, *reduce_ranges)` - The identity element (`CONST`) and the `RANGE` UOps defining the reduction loops.\n",
    "*   **Stage:** Lowering (created from `REDUCE_AXIS`).\n",
    "*   **Notes:** Lowered `REDUCE_AXIS` becomes `DEFINE_ACC -> ALU -> ASSIGN(acc)`.\n",
    "\n",
    "#### `LOAD`\n",
    "*   **Description:** Loads data from memory (global or local).\n",
    "*   **Purpose:** Reading data from a buffer into registers/variables for computation.\n",
    "*   **Args:** Optional load configuration (e.g., cache hints, not currently used extensively).\n",
    "*   **Sources:**\n",
    "    *   Old style (pre-linearize): `(BUFFER, VIEW, Optional[STORE])` - Buffer, ShapeTracker view, optional dependency.\n",
    "    *   New style (post-linearize): `(INDEX, Optional[alt_value], Optional[gate], Optional[BARRIER])` - Indexed address, value if gate is false, gate condition, barrier dependency.\n",
    "*   **Stage:** Lowering, Codegen.\n",
    "*   **Notes:** Validity checks (from `ShapeTracker` masks) are incorporated into the `INDEX` or `gate`.\n",
    "\n",
    "#### `STORE`\n",
    "*   **Description:** Stores data into memory (global or local).\n",
    "*   **Purpose:** Writing computation results back to a buffer.\n",
    "*   **Args:** None.\n",
    "*   **Sources:**\n",
    "    *   Old style (pre-linearize): `(BUFFER, VIEW, value)` - Buffer, ShapeTracker view, value to store.\n",
    "    *   New style (post-linearize): `(INDEX, value, Optional[gate])` - Indexed address, value to store, optional gate condition.\n",
    "*   **Stage:** Lowering, Codegen.\n",
    "*   **Notes:** Often the final operation(s) feeding into a `SINK`.\n",
    "\n",
    "---\n",
    "\n",
    "### Core Compute / ALU Ops\n",
    "\n",
    "These perform basic element-wise arithmetic, logical, comparison, and transcendental operations. They generally expect sources to have the same shape and dtype (except for comparisons and specific cases like `WHERE`).\n",
    "\n",
    "#### Unary (`EXP2`, `LOG2`, `SIN`, `SQRT`, `RECIP`, `NEG`)\n",
    "*   **Description:** Apply standard unary mathematical functions.\n",
    "*   **Purpose:** Element-wise computation.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** All stages.\n",
    "*   **Notes:** `NEG` is often represented as `x * -1`. Transcendental ops (`EXP2`, `LOG2`, `SIN`) might be rewritten to use approximations or backend-specific implementations.\n",
    "\n",
    "#### Binary (`ADD`, `MUL`, `IDIV`, `MAX`, `MOD`, `CMPLT`, `CMPNE`, `XOR`, `SHL`, `SHR`, `OR`, `AND`, `SUB`, `FDIV`, `POW`)\n",
    "*   **Description:** Apply standard binary mathematical or logical functions.\n",
    "*   **Purpose:** Element-wise computation between two operands.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(UOp, UOp)` - The two input UOps.\n",
    "*   **Stage:** All stages.\n",
    "*   **Notes:**\n",
    "    *   Commutative ops (`ADD`, `MUL`, `MAX`, `CMPNE`, `XOR`, `AND`, `OR`) might have sources swapped during optimization.\n",
    "    *   `IDIV` is integer division (truncates towards zero). `FDIV` (internal) represents float division (`x / y`), often lowered to `x * RECIP(y)`.\n",
    "    *   `CMPLT`/`CMPNE` output `bool` dtype.\n",
    "    *   `SUB` is often represented as `x + (-y)`.\n",
    "\n",
    "#### Ternary (`WHERE`, `MULACC`)\n",
    "*   **Description:** Apply standard ternary functions.\n",
    "*   **Purpose:** Element-wise computation involving three operands.\n",
    "*   **Args:** None.\n",
    "*   **Sources:**\n",
    "    *   `WHERE`: `(condition, true_value, false_value)` - Condition must be `bool`.\n",
    "    *   `MULACC`: `(a, b, c)` - Computes `a * b + c`.\n",
    "*   **Stage:** All stages.\n",
    "*   **Notes:** `MULACC` (Multiply-Accumulate) can often map efficiently to hardware FMA (Fused Multiply-Add) instructions.\n",
    "\n",
    "#### `CAST`\n",
    "*   **Description:** Changes the data type of the elements.\n",
    "*   **Purpose:** Type conversion (e.g., float to int, int to float, float16 to float32).\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** All stages.\n",
    "*   **Notes:** Behavior depends on the source and destination types (truncation, rounding, etc.).\n",
    "\n",
    "#### `BITCAST`\n",
    "*   **Description:** Reinterprets the bits of the elements as a different data type of the *same size*.\n",
    "*   **Purpose:** Low-level manipulation, often used for specific algorithms or interacting with hardware types (e.g., float <-> int).\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** All stages.\n",
    "*   **Notes:** Does not change the underlying bit pattern, only the type interpretation. Requires source and destination dtypes to have the same `itemsize`.\n",
    "\n",
    "---\n",
    "\n",
    "### Reduce Ops\n",
    "\n",
    "#### `REDUCE_AXIS`\n",
    "*   **Description:** Performs a reduction operation (like sum, max) along specified axes.\n",
    "*   **Purpose:** Aggregates data across dimensions.\n",
    "*   **Args:** `(Ops, tuple[int, ...])` - The reduction operation (e.g., `Ops.ADD`, `Ops.MAX`) and the axes to reduce.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** High-level, Lowering.\n",
    "*   **Notes:** Lowered into a combination of `DEFINE_ACC`, `RANGE` loops, `ALU` ops, and `ASSIGN`. Can be split or grouped during optimization.\n",
    "\n",
    "#### `WMMA` (Warp Matrix Multiply Accumulate)\n",
    "*   **Description:** Represents a hardware-accelerated matrix multiplication operation performed cooperatively by a group of threads (warp/wavefront).\n",
    "*   **Purpose:** Leverages specialized hardware units (like Tensor Cores on NVIDIA GPUs, Matrix Cores on AMD GPUs, AMX on Apple Silicon) for high-performance matrix multiplication.\n",
    "*   **Args:** `(name, dims, dtype_in, dtype_out, device, threads, upcast_axes, reduce_axes)` - Detailed configuration for the WMMA operation.\n",
    "*   **Sources:** `(A, B, C)` - Input matrices A, B, and accumulator C.\n",
    "*   **Stage:** Codegen (inserted by optimization passes like `apply_tensor_cores`).\n",
    "*   **Notes:** Highly backend-specific. Requires specific data layouts and operand types.\n",
    "\n",
    "---\n",
    "\n",
    "### Control Flow Ops\n",
    "\n",
    "#### `RANGE`\n",
    "*   **Description:** Represents a loop range, typically used for iterating over tensor dimensions.\n",
    "*   **Purpose:** Defines the iteration space for loops in the generated code.\n",
    "*   **Args:** `int` - An identifier for the loop variable (axis index).\n",
    "*   **Sources:** `(start, end)` - UOps defining the start (inclusive) and end (exclusive) of the loop.\n",
    "*   **Stage:** Lowering (created by `get_index`), Codegen.\n",
    "*   **Notes:** Rendered as `for` loops in C-style backends. Used as sources for `DEFINE_ACC`.\n",
    "\n",
    "#### `IF`\n",
    "*   **Description:** Represents a conditional block.\n",
    "*   **Purpose:** Conditional execution in the generated code.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(condition, Optional[BARRIER])` - The boolean condition UOp and an optional barrier dependency.\n",
    "*   **Stage:** Lowering, Codegen.\n",
    "*   **Notes:** Requires a corresponding `ENDIF`. Code between `IF` and `ENDIF` is executed only if the condition is true. Used for gating `LOAD`/`STORE`.\n",
    "\n",
    "#### `ENDRANGE` / `ENDIF`\n",
    "*   **Description:** Marks the end of a `RANGE` or `IF` block, respectively.\n",
    "*   **Purpose:** Defines the scope of loops and conditionals.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(RANGE,)` or `(IF,)` - The corresponding start block UOp.\n",
    "*   **Stage:** Lowering, Codegen.\n",
    "*   **Notes:** Rendered as closing braces `}` in C-style backends.\n",
    "\n",
    "#### `BARRIER`\n",
    "*   **Description:** Represents a synchronization point, typically for local (shared) memory.\n",
    "*   **Purpose:** Ensures that all threads in a workgroup reach this point before any thread proceeds, making writes to shared memory visible to other threads.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** Usually `(STORE,)` operations to local memory that need to complete before subsequent reads. Can also be a source for `IF`.\n",
    "*   **Stage:** Lowering, Codegen.\n",
    "*   **Notes:** Essential for correctness when using shared memory for reductions or caching.\n",
    "\n",
    "---\n",
    "\n",
    "### Vectorization / Structure Ops\n",
    "\n",
    "#### `VECTORIZE`\n",
    "*   **Description:** Combines multiple scalar UOps into a single vector UOp.\n",
    "*   **Purpose:** Explicitly represents vector operations for backends that support them. Also used internally as a structural node (e.g., for `VCONST`).\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(scalar_uop_1, scalar_uop_2, ...)` - The scalar UOps to be combined.\n",
    "*   **Stage:** Codegen, Final Rendering.\n",
    "*   **Notes:** The inverse of `GEP`. Renderers translate this into vector types and operations if supported.\n",
    "\n",
    "#### `UNROLL`\n",
    "*   **Description:** Represents loop unrolling during code generation. Structurally similar to `VECTORIZE` but used for axes that are fully unrolled rather than vectorized.\n",
    "*   **Purpose:** Optimization to reduce loop overhead by duplicating the loop body. Also used structurally in Tensor Core lowering.\n",
    "*   **Args:** `tuple[tuple[int, int], ...]` - The axes being unrolled and their sizes `((axis, size), ...)`.\n",
    "*   **Sources:** `(UOp,)` - The UOp whose unrolled axes are represented.\n",
    "*   **Stage:** Codegen (inserted by `Kernel.apply_opt`), Expansion.\n",
    "*   **Notes:** The expander pass (`do_expand`) processes `UNROLL` ops, effectively performing the unrolling by duplicating and adjusting source UOps.\n",
    "\n",
    "#### `CONTRACT`\n",
    "*   **Description:** Represents the contraction (summation) part of a vectorized reduction or Tensor Core operation. Inverse of `UNROLL` for specific axes.\n",
    "*   **Purpose:** Used structurally during the expansion/contraction passes related to vectorization and Tensor Cores.\n",
    "*   **Args:** `tuple[tuple[int, int], ...]` - The axes being contracted and their sizes `((axis, size), ...)`.\n",
    "*   **Sources:** `(UOp,)` - The UOp (often an `UNROLL`) being contracted.\n",
    "*   **Stage:** Expansion.\n",
    "\n",
    "#### `CAT`\n",
    "*   **Description:** Concatenates multiple vector UOps. (Internal use).\n",
    "*   **Purpose:** Used during expansion/vectorization passes to combine vectors.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** Multiple vector UOps.\n",
    "*   **Stage:** Expansion.\n",
    "*   **Notes:** Lowered to `VECTORIZE` with `GEP` sources before rendering.\n",
    "\n",
    "---\n",
    "\n",
    "### Internal / Removed Early Ops\n",
    "\n",
    "These ops exist briefly during graph construction or early simplification but are typically removed before significant lowering or scheduling.\n",
    "\n",
    "#### `CONTIGUOUS` / `CONTIGUOUS_BACKWARD`\n",
    "*   **Description:** Marks a requirement for the data to be in contiguous memory layout. `CONTIGUOUS_BACKWARD` affects the backward pass only.\n",
    "*   **Purpose:** Triggers realization or specific memory layouts. Often used before operations that require contiguous inputs (like some `COPY` operations or external calls).\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** Graph Construction, Early Simplification.\n",
    "*   **Notes:** Usually removed by simplification rules (`sym`) if the input is already known to be contiguous or if the operation can be achieved via a `VIEW`.\n",
    "\n",
    "#### `DETACH`\n",
    "*   **Description:** Removes the UOp from the computation graph for gradient calculation purposes.\n",
    "*   **Purpose:** Implements `Tensor.detach()`.\n",
    "*   **Args:** None.\n",
    "*   **Sources:** `(UOp,)` - The input UOp.\n",
    "*   **Stage:** Graph Construction, Early Simplification.\n",
    "*   **Notes:** Removed by simplification rules (`sym`).\n",
    "\n",
    "#### `BLOCK` / `BLOCKSTART` / `BLOCKFORK` / `BLOCKEND`\n",
    "*   **Description:** Internal ops used by `linearize_uop` to group UOps into basic blocks based on control flow (`RANGE`, `IF`).\n",
    "*   **Purpose:** Facilitates structuring the UOp list into code blocks for rendering.\n",
    "*   **Args:** `BasicBlock` or `int`.\n",
    "*   **Sources:** Variable, depending on the block structure.\n",
    "*   **Stage:** Codegen (`linearize_uop`).\n",
    "*   **Notes:** These are temporary structural nodes used only within the linearization process and do not appear in the final UOp list passed to the renderer.\n",
    "\n",
    "---\n",
    "\n",
    "This summary covers the primary UOps and their roles. The exact behavior and interactions can be complex, as they are subject to numerous rewrite rules during the compilation process."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
