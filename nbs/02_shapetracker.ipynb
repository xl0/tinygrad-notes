{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - View and ShapeTracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So far we have been making scalar UOps that don't have a shape associated with them.\n",
    "\n",
    "While we have been getting away with it so far, the UOp trees we made are not really valid without a shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CPU\"] = \"1\"\n",
    "os.environ[\"DEBUG\"]=\"4\"\n",
    "\n",
    "import tinygrad as tg\n",
    "from tinygrad import Tensor, dtypes\n",
    "from tinygrad.ops import UOp, Ops\n",
    "from tinygrad.spec import type_verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UOp(Ops.CONST, dtypes.float, arg=1.0, src=())"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = UOp.const(dtypes.float, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import linecache\n",
    "\n",
    "def print_last_frame_context(exception, num_lines=2):\n",
    "    # Get the last frame from the traceback\n",
    "    tb = traceback.extract_tb(sys.exc_info()[2])\n",
    "    last_frame = tb[-1]\n",
    "\n",
    "    # Unpack frame info\n",
    "    filename, lineno, funcname, line = last_frame\n",
    "\n",
    "    # Print location info\n",
    "    print(f\"{type(exception).__name__} in {filename}:{lineno} in {funcname}()\")\n",
    "\n",
    "    # Get surrounding lines\n",
    "    start = max(lineno - num_lines, 1)\n",
    "    end = lineno + num_lines\n",
    "\n",
    "    # Print code context\n",
    "    print(\"\\nCode context:\")\n",
    "    for i in range(start, end + 1):\n",
    "        line = linecache.getline(filename, i).rstrip()\n",
    "        prefix = \"--->\" if i == lineno else \"    \"\n",
    "        print(f\"{prefix} {i:4d} {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssertionError in /home/xl0/work/projects/grads/tinygrad/tinygrad/helpers.py:61 in unwrap()\n",
      "\n",
      "Code context:\n",
      "       59   return ret\n",
      "       60 def unwrap(x:Optional[T]) -> T:\n",
      "--->   61   assert x is not None\n",
      "       62   return x\n",
      "       63 def get_single_element(x:list[T]) -> T:\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(a.shape)\n",
    "except Exception as e:\n",
    "    print_last_frame_context(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we were missing is the device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssertionError in /home/xl0/work/projects/grads/tinygrad/tinygrad/helpers.py:61 in unwrap()\n",
      "\n",
      "Code context:\n",
      "       59   return ret\n",
      "       60 def unwrap(x:Optional[T]) -> T:\n",
      "--->   61   assert x is not None\n",
      "       62   return x\n",
      "       63 def get_single_element(x:list[T]) -> T:\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(a.device)\n",
    "except Exception as e:\n",
    "    print_last_frame_context(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this real quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UOp(Ops.CONST, dtypes.float, arg=1.0, src=(\n",
       "  UOp(Ops.VIEW, dtypes.void, arg=ShapeTracker(views=(View(shape=(0,), strides=(0,), offset=0, mask=None, contiguous=True),)), src=(\n",
       "    UOp(Ops.DEVICE, dtypes.void, arg='CPU', src=()),)),))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinygrad.shape.shapetracker import ShapeTracker, View\n",
    "\n",
    "a = UOp.const(dtypes.float, 1).replace(src=(\n",
    "        UOp(Ops.VIEW, dtypes.void, arg=ShapeTracker.from_shape( (0,) ), src=(\n",
    "            UOp(Ops.DEVICE, dtypes.void, arg=\"CPU\", src=()),)),))\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPU'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better.\n",
    "\n",
    "Now, what's up with that `ShapeTracker` and `View`. Let's start with the later.\n",
    "\n",
    "## View\n",
    "\n",
    "You are probably familiar with how shape and strides work in Pytorch or Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29, 30, 31]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(0, 31, 32, dtype=torch.int32).view(4, 8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape defined the, well, the shape of the array. It can have any number of dimensions (2 in this case), and each dimension has its size.\n",
    "\n",
    "A Tensor is just a linear array, and the shape is there for convenience, because we usually want to work with multi-dimensional data.\n",
    "\n",
    "We can change the shape, as long as the number of elements in the new shape stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]],\n",
       "\n",
       "        [[16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [24, 25, 26, 27],\n",
       "         [28, 29, 30, 31]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.view(2,4,4) # This creates a view that refers to the same data, but now it's seen as a 3-d array.\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stride tells us how many elements do we need to move in the underlying 1-d array (base), to get to the next element in the given dimension.\n",
    "\n",
    "For out 2x4x4 array, to move 1 element in the row (last dimension), we need to move ... 1 element in the base.\n",
    "\n",
    "And to move by one element in the column dimension, we need to move by 4 elements in the base, because each row is 4 elements.\n",
    "\n",
    "> This is the standard `C`, or `row-major` order format for multidimensional data.\n",
    "\n",
    "> ![Row-major and Column-major order](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Row_and_column_major_order.svg/255px-Row_and_column_major_order.svg.png)\n",
    "\n",
    "> You might have seen references to the `F`, or `column-major` order at some point. Historically this is how data was stored in Fortran, and I'm sure they had their reasons for it, but it's definitely less intuitive.\n",
    "\n",
    "To move in the next dimension, we'd have to skip 4 columns, and for each column we skip 4 elements, so 16 in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if the stride always matched the shape, things would be boring. We can set the stride independently.\n",
    "\n",
    "Let's go back to our 4x8 view to make things easies. In this case we need to skip 8 elements to move by one row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29, 30, 31]], dtype=torch.int32)\n",
      "Shape:  torch.Size([4, 8])\n",
      "Stride: (8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(\"Shape: \",a.shape)\n",
    "print(\"Stride:\",a.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to create a view that would skip every other element in the rows? We can do this by creatig a view with shape (torch refers to it as `size`) 4x4, and stride (8, 2)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2,  4,  6],\n",
       "        [ 8, 10, 12, 14],\n",
       "        [16, 18, 20, 22],\n",
       "        [24, 26, 28, 30]], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.as_strided(size=(4,4), stride=(8, 2))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify an offset from the start of the base array. This will give us the odd elements in each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  3,  5,  7],\n",
       "        [ 9, 11, 13, 15],\n",
       "        [17, 19, 21, 23],\n",
       "        [25, 27, 29, 31]], dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.as_strided(size=(4,4), stride=(8, 2), storage_offset=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a view that has the diagonal elements of `a` (0, 9, 18, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  9, 18, 27], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.as_strided(size=(4,), stride=(9,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another fun thing we can do - set one of more of the strides to 0, to duplicate (broadcast) dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.linspace(1, 4, 4, dtype=torch.int32)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3],\n",
       "        [4, 4, 4, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.as_strided(size=(4,4), stride=(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each step in the output column, we take 1 step in the base, and for each step in the output row, we don't take any steps at all!\n",
    "\n",
    "That's how `.full()` works - it creates 1 single element, and makes all elements in the Tensor refer to it by setting the strides to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.Tensor([1]).to(torch.int32)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.as_strided(size=(4,4), stride=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `View` class is intended to keep track of the shape and stride of the data. Let's play with it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View(shape=(4, 8), strides=(8, 1), offset=0, mask=None, contiguous=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = View(shape=(4,8), strides=(8,1), offset=0, mask=None, contiguous=True)\n",
    "v # A normal array 4x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29, 30, 31]], dtype=torch.int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29, 30, 31]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.as_strided(size=v.shape, stride=v.strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View(shape=(32,), strides=(1,), offset=0, mask=None, contiguous=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v32 = v.reshape( (32,) ) # 1-d array of 32 elements\n",
    "v32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.as_strided(size=v32.shape, stride=v32.strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View(shape=(4, 8), strides=(8, -1), offset=7, mask=None, contiguous=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_flip = v.flip( (False, True) ) # Flip the last dimension\n",
    "v_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError in /tmp/ipykernel_606682/772861321.py:2 in <module>()\n",
      "\n",
      "Code context:\n",
      "--->    2     a.as_strided(size=v_flip.shape, stride=v_flip.strides)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a.as_strided(size=v_flip.shape, stride=v_flip.strides)\n",
    "except Exception as e:\n",
    "    print_last_frame_context(e, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, torch actually does not support negative strides. This should have looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  6,  5,  4,  3,  2,  1,  0],\n",
       "        [15, 14, 13, 12, 11, 10,  9,  8],\n",
       "        [23, 22, 21, 20, 19, 18, 17, 16],\n",
       "        [31, 30, 29, 28, 27, 26, 25, 24]], dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flip((1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what's up with the mask? It allows us to create arrays with elements that are outside of the underlying storage!\n",
    "\n",
    "For example, if we want to pad a 2-d array, we don't want to allocate a new array - just mark the padded elements as being not valid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View(shape=(4, 8), strides=(8, 1), offset=0, mask=None, contiguous=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View(shape=(6, 10), strides=(8, 1), offset=-9, mask=((1, 5), (1, 9)), contiguous=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.pad( ((1,1,),( 1, 1)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch does not allow negative offsets either, but I think the idea is clear:\n",
    "\n",
    "![](pad-view.png){width=70% fig-align=\"left\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
